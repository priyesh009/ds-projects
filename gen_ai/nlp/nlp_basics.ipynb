{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a57ee9",
   "metadata": {},
   "source": [
    "## Tokenization exmaple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "091106d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello priyesh wlecome. lavdya zhatu zaada. I live in Indy!, I am eve's BF\n"
     ]
    }
   ],
   "source": [
    "corpus = \"\"\" Hello priyesh wlecome. lavdya zhatu zaada. I live in Indy!, I am eve's BF\"\"\"\n",
    "print(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43f4ca4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Hello priyesh wlecome.',\n",
       " 'lavdya zhatu zaada.',\n",
       " \"I live in Indy!, I am eve's BF\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize, wordpunct_tokenize\n",
    "\n",
    "sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a451ceef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'priyesh',\n",
       " 'wlecome',\n",
       " '.',\n",
       " 'lavdya',\n",
       " 'zhatu',\n",
       " 'zaada',\n",
       " '.',\n",
       " 'I',\n",
       " 'live',\n",
       " 'in',\n",
       " 'Indy',\n",
       " '!',\n",
       " ',',\n",
       " 'I',\n",
       " 'am',\n",
       " 'eve',\n",
       " \"'s\",\n",
       " 'BF']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15c68d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'priyesh',\n",
       " 'wlecome',\n",
       " '.',\n",
       " 'lavdya',\n",
       " 'zhatu',\n",
       " 'zaada',\n",
       " '.',\n",
       " 'I',\n",
       " 'live',\n",
       " 'in',\n",
       " 'Indy',\n",
       " '!,',\n",
       " 'I',\n",
       " 'am',\n",
       " 'eve',\n",
       " \"'\",\n",
       " 's',\n",
       " 'BF']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742808bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "543058a5",
   "metadata": {},
   "source": [
    "### Stemming \n",
    "\n",
    "Process to reduce word to its Stem. Example, Go, going, gone = go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "32185b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Porter stemming\n",
    "\n",
    "## There is alos Snowallsstemmer and Regxestemmer both also have limitation\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "words = ['eating','eaten','eat', 'Go', 'going', 'gone']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cdabfe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8827dbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating ---- > eat\n",
      "eaten ---- > eaten\n",
      "eat ---- > eat\n",
      "Go ---- > go\n",
      "going ---- > go\n",
      "gone ---- > gone\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word, \"---- >\", stemming.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00158d0",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "\n",
    "The output will be root word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba1fc3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/priyesh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/priyesh/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/priyesh/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "nltk.download('omw-1.4')  # Optional but helps with lemmatization accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fdcb1b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d945c96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"going\",pos='v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fa9eb8",
   "metadata": {},
   "source": [
    "### Stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1c9f9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/priyesh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c04f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"\n",
    "\n",
    "\"Dream, dream, dream. Dreams transform into thoughts, and thoughts result in action.\n",
    "\n",
    "When you think about the future, it is important to understand the relationship between the past, present, and future. We all have the potential to achieve greatness, but we need to dream big and think positively. We must make an effort to move forward, in spite of the obstacles we face.\n",
    "\n",
    "The purpose of life is not to be happy but to be useful, honorable, and compassionate. To be someone who makes a positive difference to the world. We should dream and try to reach the stars. By striving for success, we will not only change our destiny but will also change the world for the better.\n",
    "\n",
    "When we stand up and take action, we must act with integrity, honesty, and a strong sense of purpose. I firmly believe that greatness is not an individual pursuit but something achieved through teamwork, mutual respect, and collaboration.\n",
    "\n",
    "Do not be afraid of challenges. In fact, embrace them, for they are the stepping stones to success.\n",
    "\n",
    "To my young friends, I say: \"You are the leaders of tomorrow. You have the potential to make a huge difference. Be the change you want to see in the world.\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "097205b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n\"Dream, dream, dream.',\n",
       " 'Dreams transform into thoughts, and thoughts result in action.',\n",
       " 'When you think about the future, it is important to understand the relationship between the past, present, and future.',\n",
       " 'We all have the potential to achieve greatness, but we need to dream big and think positively.',\n",
       " 'We must make an effort to move forward, in spite of the obstacles we face.',\n",
       " 'The purpose of life is not to be happy but to be useful, honorable, and compassionate.',\n",
       " 'To be someone who makes a positive difference to the world.',\n",
       " 'We should dream and try to reach the stars.',\n",
       " 'By striving for success, we will not only change our destiny but will also change the world for the better.',\n",
       " 'When we stand up and take action, we must act with integrity, honesty, and a strong sense of purpose.',\n",
       " 'I firmly believe that greatness is not an individual pursuit but something achieved through teamwork, mutual respect, and collaboration.',\n",
       " 'Do not be afraid of challenges.',\n",
       " 'In fact, embrace them, for they are the stepping stones to success.',\n",
       " 'To my young friends, I say: \"You are the leaders of tomorrow.',\n",
       " 'You have the potential to make a huge difference.',\n",
       " 'Be the change you want to see in the world.\"']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8122f2c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
